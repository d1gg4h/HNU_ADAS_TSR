{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ff5xeIGvpp-B"
   },
   "source": [
    "# Proof of Concept für Cloud basierende Jupyter Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eRqS4hoCnA9d"
   },
   "source": [
    "## Testabschnitt\n",
    "Dies ist ein jupyter notebook testdatei (proof of concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "T2JW6toCg_pQ",
    "outputId": "a23b35c7-0fe3-484a-c52b-86b0d83f2089"
   },
   "outputs": [],
   "source": [
    "s_in_min = 60\n",
    "s_in_h = s_in_min*60\n",
    "s_in_d = s_in_h*24\n",
    "\n",
    "print(\"Der Tag hat \"+ str(s_in_d) + \" Sekunden\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZZrIS0ispGoB"
   },
   "source": [
    "## Maschinelles Lernen mit neuronalen Netzen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mv-ifk6Vnl3K"
   },
   "source": [
    "Hier starten wir mit dem Abschnitt *machine learning*. Dabei verwenden wir die Deep-Learning-Bibliothek **Keras**, welche das **TensorFlow** Framework verwendet.\n",
    "### Voraussetzungen\n",
    "Für dieses Notebook wird die Bilderdatenbank **GTSRB** benötigt, welche unter diesem [Link](https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/published-archive.html) heruntergeladen werden kann.\n",
    "Benötigt wird die **GTSRB_Final_Training_Images.zip** für das anlernen des *neuronalen Netzes*.\n",
    "### Import\n",
    "Zu Beginn müssen die benötigten Packages importiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UFX2hzMlhcFn"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob \n",
    "import cv2\n",
    "import os\n",
    " \n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.color import rgb2grey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sSjdHfCh1yL0"
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 43\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YTTuvuGarElN"
   },
   "source": [
    "### Vorbereiten der Test- und Trainingdaten\n",
    "In diesem Abschnitt legen wir fest wo sich die Trainingdateien befinden. Dabei muss der Pfad entsprechend angepasst werden.\n",
    "Wenn  das Notebook lokal ausgeführt wird, reicht der relative Pfad aus. Bei einer Cloud Ausführung muss der komplette Dateipfad angegeben werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DPPaZ3MmtdV5"
   },
   "outputs": [],
   "source": [
    "# Pfad zu den Trainingsdaten\n",
    "data_path = \"src/GTSRB/Final_Training/Images\" #Hier habe ich die .zip im Ordner \"src\" entpakt und die bestehende Ordnerstruktur genutzt\n",
    " \n",
    "images = []\n",
    "image_labels = []\n",
    " \n",
    "# Pfade zu den einzelnen Bildern\n",
    "for i in range(NUM_CLASSES):\n",
    "    image_path = data_path + \"/\" + format(i, \"05d\") + \"/\"\n",
    "    for img in glob.glob(image_path + \"*.ppm\"):\n",
    "        image = cv2.imread(img)\n",
    "        image = rgb2grey(image) # Umwandlung in Graustufen\n",
    "        image = (image / 255.0) # Neu skalieren\n",
    "        image = cv2.resize(image, (32, 32)) #Größe vereinheitlichen\n",
    "        images.append(image)\n",
    "        \n",
    "        # Erstellung der Label für die Bilder und Transfer in eine Binär-Matrix (1-aus-n-Code)\n",
    "        labels = np.zeros((NUM_CLASSES, ), dtype=np.float32)\n",
    "        labels[i] = 1.0\n",
    "        image_labels.append(labels)\n",
    " \n",
    "images = np.stack([img[:, :, np.newaxis] for img in images], axis=0).astype(np.float32)\n",
    "image_labels = np.matrix(image_labels).astype(np.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m75xGArGE7Eq"
   },
   "source": [
    "Nun lassen wir us die Form der Bilder anzeigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "outYVTLSEziq"
   },
   "outputs": [],
   "source": [
    "plt.imshow(images[45, :, :, :].reshape(32, 32), cmap=\"gray\")\n",
    "print(image_labels[45, :])\n",
    "\n",
    "print(images.shape)\n",
    "print(len(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F6dGGxzBE6pQ"
   },
   "source": [
    "Wir teilen die Testbilder in Traings und Testbilder auf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G9op-s_mE5sK"
   },
   "outputs": [],
   "source": [
    "(train_X, test_X, train_y, test_y) = train_test_split(images, image_labels, \n",
    "                                                      test_size=0.2, \n",
    "                                                      random_state=42)\n",
    "print(train_X.shape)\n",
    "print(train_y.shape)\n",
    "print(test_X.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RU4aRV8pFM4A"
   },
   "source": [
    "### Erstellung des Models\n",
    "Wir verwenden drei Conv2D() (Dreidimensionale Faltung) Layer mit den Dimensionen 32, 64 und 128. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uaTfmXOdFMRQ"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "input_shape = (32, 32, 1) # Bilder mit der Auflösung von 32x32 Pixel und Graustufe\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(32, (5, 5), padding='same', activation='relu', input_shape=input_shape, data_format=\"channels_last\"))\n",
    "model.add(tf.keras.layers.BatchNormalization(axis=-1))      \n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "        \n",
    "model.add(tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='relu', data_format=\"channels_last\"))\n",
    "model.add(tf.keras.layers.BatchNormalization(axis=-1))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(128, (5, 5), padding='same', activation='relu', data_format=\"channels_last\"))\n",
    "model.add(tf.keras.layers.BatchNormalization(axis=-1))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dropout(0.4))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(43, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WHrGHmjBGqQZ"
   },
   "source": [
    "### Kompilierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A9ghN40fGuYg"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_X, train_y, validation_data=(test_X, test_y),epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DLpSVEU9GyCH"
   },
   "source": [
    "### Diagramm zum Verlust und Genauigkeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q4K0cXNVGxzQ"
   },
   "outputs": [],
   "source": [
    "#Plot für Diagramm\n",
    "num_epochs = np.arange(0, 10)\n",
    "plt.figure(dpi=300)\n",
    "plt.plot(num_epochs, history.history['loss'], label='train_loss', c='blue')\n",
    "plt.plot(num_epochs, history.history['val_loss'], label='val_loss', c='red')\n",
    "plt.plot(num_epochs, history.history['acc'], label='train_acc', c='green')\n",
    "plt.plot(num_epochs, history.history['val_acc'], label='val_acc', c='yellow')\n",
    "plt.title('Wert der Verlustfunktion')\n",
    "plt.xlabel('Epochen')\n",
    "plt.ylabel('Genauigkeit bzw. Verlust')\n",
    "plt.legend()\n",
    "plt.savefig('Diagramm.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "POC_IPYNB_GTSRB.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

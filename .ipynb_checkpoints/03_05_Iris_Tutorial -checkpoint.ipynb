{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial Session Iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daten laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal_length  sepal_width  petal_length  petal_width         species\n",
      "0             5.1          3.5           1.4          0.2     Iris-setosa\n",
      "1             4.9          3.0           1.4          0.2     Iris-setosa\n",
      "2             4.7          3.2           1.3          0.2     Iris-setosa\n",
      "3             4.6          3.1           1.5          0.2     Iris-setosa\n",
      "4             5.0          3.6           1.4          0.2     Iris-setosa\n",
      "..            ...          ...           ...          ...             ...\n",
      "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
      "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
      "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
      "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
      "149           5.9          3.0           5.1          1.8  Iris-virginica\n",
      "\n",
      "[150 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./src/iris.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels von String nach Int umformen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal_length  sepal_width  petal_length  petal_width  species\n",
      "0             5.1          3.5           1.4          0.2        0\n",
      "1             4.9          3.0           1.4          0.2        0\n",
      "2             4.7          3.2           1.3          0.2        0\n",
      "3             4.6          3.1           1.5          0.2        0\n",
      "4             5.0          3.6           1.4          0.2        0\n",
      "..            ...          ...           ...          ...      ...\n",
      "145           6.7          3.0           5.2          2.3        2\n",
      "146           6.3          2.5           5.0          1.9        2\n",
      "147           6.5          3.0           5.2          2.0        2\n",
      "148           6.2          3.4           5.4          2.3        2\n",
      "149           5.9          3.0           5.1          1.8        2\n",
      "\n",
      "[150 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "species_to_int = {'Iris-setosa': 0, 'Iris-versicolor' : 1, 'Iris-virginica': 2}\n",
    "df['species'] = df['species'].map(species_to_int)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trennung der labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "X= df.iloc[:,:-1].values\n",
    "y= df.iloc[:, -1].values\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ãœbertrag der Labels in 2 dim Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "y1 = encoder.fit_transform(y)\n",
    "Y = pd.get_dummies(y1).values\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erstellung des Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "G:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "G:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "G:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "G:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "G:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From G:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(12, input_shape=(4, ), activation='relu'))\n",
    "model.add(layers.Dense(6, activation='relu'))\n",
    "model.add(layers.Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 12)                60        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 78        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 21        \n",
      "=================================================================\n",
      "Total params: 159\n",
      "Trainable params: 159\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From G:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "120/120 [==============================] - 0s 1ms/step - loss: 2.7178 - accuracy: 0.3333\n",
      "Epoch 2/50\n",
      "120/120 [==============================] - 0s 42us/step - loss: 2.5559 - accuracy: 0.3333\n",
      "Epoch 3/50\n",
      "120/120 [==============================] - 0s 42us/step - loss: 2.3917 - accuracy: 0.3333\n",
      "Epoch 4/50\n",
      "120/120 [==============================] - 0s 42us/step - loss: 2.2413 - accuracy: 0.3333\n",
      "Epoch 5/50\n",
      "120/120 [==============================] - 0s 42us/step - loss: 2.1006 - accuracy: 0.3333\n",
      "Epoch 6/50\n",
      "120/120 [==============================] - 0s 42us/step - loss: 1.9738 - accuracy: 0.3333\n",
      "Epoch 7/50\n",
      "120/120 [==============================] - 0s 42us/step - loss: 1.8454 - accuracy: 0.3333\n",
      "Epoch 8/50\n",
      "120/120 [==============================] - 0s 42us/step - loss: 1.7298 - accuracy: 0.3333\n",
      "Epoch 9/50\n",
      "120/120 [==============================] - 0s 33us/step - loss: 1.6229 - accuracy: 0.3333\n",
      "Epoch 10/50\n",
      "120/120 [==============================] - 0s 42us/step - loss: 1.5288 - accuracy: 0.3333\n",
      "Epoch 11/50\n",
      "120/120 [==============================] - 0s 33us/step - loss: 1.4384 - accuracy: 0.3333\n",
      "Epoch 12/50\n",
      "120/120 [==============================] - 0s 42us/step - loss: 1.3595 - accuracy: 0.3333\n",
      "Epoch 13/50\n",
      "120/120 [==============================] - 0s 42us/step - loss: 1.2990 - accuracy: 0.3333\n",
      "Epoch 14/50\n",
      "120/120 [==============================] - 0s 42us/step - loss: 1.2387 - accuracy: 0.3333\n",
      "Epoch 15/50\n",
      "120/120 [==============================] - 0s 50us/step - loss: 1.1863 - accuracy: 0.3333\n",
      "Epoch 16/50\n",
      "120/120 [==============================] - 0s 42us/step - loss: 1.1427 - accuracy: 0.3333\n",
      "Epoch 17/50\n",
      "120/120 [==============================] - 0s 33us/step - loss: 1.1014 - accuracy: 0.3333\n",
      "Epoch 18/50\n",
      "120/120 [==============================] - 0s 42us/step - loss: 1.0646 - accuracy: 0.3333\n",
      "Epoch 19/50\n",
      "120/120 [==============================] - 0s 41us/step - loss: 1.0322 - accuracy: 0.3417\n",
      "Epoch 20/50\n",
      "120/120 [==============================] - 0s 42us/step - loss: 1.0054 - accuracy: 0.3750\n",
      "Epoch 21/50\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.9834 - accuracy: 0.4000\n",
      "Epoch 22/50\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.9675 - accuracy: 0.4500\n",
      "Epoch 23/50\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.9546 - accuracy: 0.5417\n",
      "Epoch 24/50\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.9453 - accuracy: 0.6167\n",
      "Epoch 25/50\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.9371 - accuracy: 0.6583\n",
      "Epoch 26/50\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.9296 - accuracy: 0.6750\n",
      "Epoch 27/50\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.9224 - accuracy: 0.6833\n",
      "Epoch 28/50\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.9157 - accuracy: 0.7417\n",
      "Epoch 29/50\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.9089 - accuracy: 0.7500\n",
      "Epoch 30/50\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.9024 - accuracy: 0.7333\n",
      "Epoch 31/50\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.8960 - accuracy: 0.7083\n",
      "Epoch 32/50\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.8900 - accuracy: 0.6917\n",
      "Epoch 33/50\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.8837 - accuracy: 0.6833\n",
      "Epoch 34/50\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.8778 - accuracy: 0.6750\n",
      "Epoch 35/50\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.8715 - accuracy: 0.6917\n",
      "Epoch 36/50\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.8658 - accuracy: 0.6917\n",
      "Epoch 37/50\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.8594 - accuracy: 0.7000\n",
      "Epoch 38/50\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.8538 - accuracy: 0.7083\n",
      "Epoch 39/50\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.8477 - accuracy: 0.7167\n",
      "Epoch 40/50\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.8418 - accuracy: 0.7167\n",
      "Epoch 41/50\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.8365 - accuracy: 0.7167\n",
      "Epoch 42/50\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.8312 - accuracy: 0.7250\n",
      "Epoch 43/50\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.8262 - accuracy: 0.7333\n",
      "Epoch 44/50\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.8215 - accuracy: 0.7500\n",
      "Epoch 45/50\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.8167 - accuracy: 0.7500\n",
      "Epoch 46/50\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.8121 - accuracy: 0.7417\n",
      "Epoch 47/50\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.8077 - accuracy: 0.7333\n",
      "Epoch 48/50\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.8031 - accuracy: 0.7333\n",
      "Epoch 49/50\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.7987 - accuracy: 0.7333\n",
      "Epoch 50/50\n",
      "120/120 [==============================] - 0s 33us/step - loss: 0.7946 - accuracy: 0.7250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x296a0e53548>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abspeichern des Models\n",
    "Anmerkung: bei Windows Dateipfaden muss ein \"r\"  vor den Pfad gesetzt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(r'C:/Users/Stoll/Desktop/Bachelorarbeit/test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    }
   ],
   "source": [
    "Xnew = np.array([[6.7, 3.0, 5.2, 2.3]])\n",
    "#6.7          3.0           5.2          2.3\n",
    "ynew = model.predict_classes(Xnew)\n",
    "print(ynew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
